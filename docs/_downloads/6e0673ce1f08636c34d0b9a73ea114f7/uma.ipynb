{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%%shell\n# Installs the latest dev build of TVM from PyPI. If you wish to build\n# from source, see https://tvm.apache.org/docs/install/from_source.html\npip install apache-tvm --pre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n.. _tutorial-uma:\n\nMaking your Hardware Accelerator TVM-ready with UMA\n===================================================\n**Authors**: `Michael J. Klaiber <https://github.com/MichaelJKlaiber>`_, `Christoph Gerum <https://github.com/cgerum>`_,\n`Paul Palomero Bernardo <https://github.com/PaulPalomeroBernardo/>`_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is an introductory tutorial to the **Universal Modular Accelerator Interface** (UMA).\nUMA provides an easy-to-use API to integrate new hardware accelerators into TVM.\n\nThis tutorial gives you step-by-step guidance how to use UMA to\nmake your hardware accelerator TVM-ready.\nWhile there is no one-fits-all solution for this problem, UMA targets to provide a stable and Python-only\nAPI to integrate a number of hardware accelerator classes into TVM.\n\n\nIn this tutorial you will get to know the UMA API in three use cases of increasing complexity.\nIn these use case the three mock-accelerators\n**Vanilla**, **Strawberry** and **Chocolate** are introduced and\nintegrated into TVM using UMA.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vanilla\n-------------\n**Vanilla** is a simple accelerator consisting of a MAC array and has no internal memory.\nIt is can ONLY process Conv2D layers, all other layers are executed on a CPU, that also orchestrates **Vanilla**.\nBoth the CPU and Vanilla use a shared memory.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. image:: https://raw.githubusercontent.com/apache/tvm-site/main/images/tutorial/uma_vanilla_block_diagram.png\n  :width: 100%\n  :alt: A block diagram of Vanilla\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Vanilla** has a C interface ``vanilla_conv2dnchw(...)``` for carrying out a Conv2D operation (including same-padding),\nthat accepts pointers to input feature map, weights and result,\nas well as the dimensions of `Conv2D`: `oc`, `iw`, `ih`, `ic`, `kh`, `kw`.\n\n.. code-block:: c++\n\n  int vanilla_conv2dnchw(float* ifmap, float*  weights, float*  result, int oc, int iw, int ih, int ic, int kh, int kw);\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The script `uma_cli` creates code skeletons with API-calls into the UMA-API for new accelerators.\n\nFor **Vanilla** we use it as follows: (``--tutorial vanilla`` adds all the additional files required for this part of the tutorial)\n\n.. code-block:: bash\n\n  pip install inflection\n  cd $TVM_HOME/apps/uma\n  python uma_cli.py --add_hardware vanilla_accelerator --tutorial vanilla\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "uma_cli.py generates these files in the directory ``vanilla_accelerator`` which we are going to revist.\n\n.. code-block:: bash\n\n  backend.py\n  codegen.py\n  conv2dnchw.cc\n  passes.py\n  patterns.py\n  run.py\n  strategies.py\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vanilla backend\n\n The generated backend for vanilla is found in `vanilla_accelerator/backend.py`:\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code-block:: python\n\n class VanillaAcceleratorBackend(UMABackend):\n     \"\"\"UMA backend for VanillaAccelerator.\"\"\"\n\n     def __init__(self):\n         super().__init__()\n\n         self._register_pattern(\"conv2d\", conv2d_pattern())\n         self._register_tir_pass(PassPhase.TIR_PHASE_0, VanillaAcceleratorConv2DPass())\n         self._register_codegen(fmt=\"c\", includes=gen_includes)\n\n     @property\n     def target_name(self):\n         return \"vanilla_accelerator\"\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define offloaded patterns\n\nTo specify that `Conv2D` is offloaded to **Vanilla**, it is described as Relay dataflow pattern\n(`DFPattern <https://tvm.apache.org/docs/reference/langref/relay_pattern.html>`_) in `vanilla_accelerator/patterns.py`\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code-block:: python\n\n def conv2d_pattern():\n     pattern = is_op(\"nn.conv2d\")(wildcard(), wildcard())\n     pattern = pattern.has_attr({\"strides\": [1, 1]})\n     return pattern\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To map **Conv2D** operations from the input graph  to **Vanilla**'s\nlow level function call ``vanilla_conv2dnchw(...)``, the TIR pass\n*VanillaAcceleratorConv2DPass* (that will be discussed later in this tutorial)\nis registered in `VanillaAcceleratorBackend`.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Codegen\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The file ``vanilla_accelerator/codegen.py`` defines static  C-code that is added to the\nresulting C-Code generated by TVM\u015b C-Codegen in ``gen_includes``.\nHere C-code is added to include **Vanilla**'s low level library``vanilla_conv2dnchw()``.\n\n.. code-block:: python\n\n def gen_includes() -> str:\n     topdir = pathlib.Path(__file__).parent.absolute()\n\n     includes = \"\"\n     includes += f'#include \"{topdir}/conv2dnchw.cc\"'\n     return includes\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As shown above in `VanillaAcceleratorBackend` it is registered to UMA with\nthe `self._register_codegen`\n\n.. code-block:: python\n\n  self._register_codegen(fmt=\"c\", includes=gen_includes)\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Building the Neural Network and run it on Vanilla\n\nTo demonstrate UMA's functionality, we will generate C code for a single Conv2D layer and run it on\nthe Vanilla accelerator.\nThe file ``vanilla_accelerator/run.py`` provides a demo running a Conv2D layer\nmaking use of Vanilla's C-API.\n\n\n.. code-block:: python\n\n def main():\n     mod, inputs, output_list, runner = create_conv2d()\n\n     uma_backend = VanillaAcceleratorBackend()\n     uma_backend.register()\n     mod = uma_backend.partition(mod)\n     target = tvm.target.Target(\"vanilla_accelerator\", host=tvm.target.Target(\"c\"))\n\n     export_directory = tvm.contrib.utils.tempdir(keep_for_debug=True).path\n     print(f\"Generated files are in {export_directory}\")\n     compile_and_run(\n         AOTModel(module=mod, inputs=inputs, outputs=output_list),\n         runner,\n         interface_api=\"c\",\n         use_unpacked_api=True,\n         target=target,\n         test_dir=str(export_directory),\n     )\n\n\n main()\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By running ``vanilla_accelerator/run.py`` the output files are generated in the model library format (MLF).\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n\n.. code-block:: bash\n\n  Generated files are in /tmp/tvm-debug-mode-tempdirs/2022-07-13T13-26-22___x5u76h0p/00000\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine the generated files:\n\n\nOutput:\n\n.. code-block:: bash\n\n  cd /tmp/tvm-debug-mode-tempdirs/2022-07-13T13-26-22___x5u76h0p/00000\n  cd build/\n  ls -1\n\n  codegen\n  lib.tar\n  metadata.json\n  parameters\n  runtime\n  src\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To evaluate the generated C code go to ``codegen/host/src/default_lib2.c``\n\n.. code-block:: bash\n\n  cd codegen/host/src/\n  ls -1\n\n  default_lib0.c\n  default_lib1.c\n  default_lib2.c\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In `default_lib2.c` you can now see that the generated code calls\ninto Vanilla's C-API and executes a Conv2D layer:\n\n.. code-block:: c++\n\n  TVM_DLL int32_t tvmgen_default_vanilla_accelerator_main_0(float* placeholder, float* placeholder1, float* conv2d_nchw, uint8_t* global_workspace_1_var) {\n       vanilla_accelerator_conv2dnchw(placeholder, placeholder1, conv2d_nchw, 32, 14, 14, 32, 3, 3);\n       return 0;\n  }\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Strawberry\n---------------\nComing soon ...\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Chocolate\n--------------\nComing soon ...\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Request for Community Input\n-----------------------------\nIf this tutorial **did not** fit to your accelerator, lease add your requirements to the UMA thread in\nthe TVM discuss forum: `Link <https://discuss.tvm.apache.org/t/rfc-uma-universal-modular-accelerator-interface/12039>`_.\nWe are eager to extend this tutorial to provide guidance on making further classes of AI hardware\naccelerators TVM-ready using the UMA interface.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "References\n-----------\n[UMA-RFC] `UMA: Universal Modular Accelerator Interface <https://github.com/apache/tvm-rfcs/blob/main/rfcs/0060_UMA_Unified_Modular_Accelerator_Interface.md>`_,\nTVM RFC, June 2022.\n\n[DFPattern] `Pattern Matching in Relay <https://tvm.apache.org/docs/reference/langref/relay_pattern.html>`_\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}