{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%%bash\n# Installs the latest dev build of TVM from PyPI. If you wish to build\n# from source, see https://tvm.apache.org/docs/install/from_source.html\npip install apache-tvm --pre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Making your Hardware Accelerator TVM-ready with UMA {#tutorial-uma}\n===================================================\n\n**Authors**: [Michael J. Klaiber](https://github.com/MichaelJKlaiber),\n[Christoph Gerum](https://github.com/cgerum), [Paul Palomero\nBernardo](https://github.com/PaulPalomeroBernardo/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is an introductory tutorial to the **Universal Modular Accelerator\nInterface** (UMA). UMA provides an easy-to-use API to integrate new\nhardware accelerators into TVM.\n\nThis tutorial gives you step-by-step guidance how to use UMA to make\nyour hardware accelerator TVM-ready. While there is no one-fits-all\nsolution for this problem, UMA targets to provide a stable and\nPython-only API to integrate a number of hardware accelerator classes\ninto TVM.\n\nIn this tutorial you will get to know the UMA API in three use cases of\nincreasing complexity. In these use case the three mock-accelerators\n**Vanilla**, **Strawberry** and **Chocolate** are introduced and\nintegrated into TVM using UMA.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vanilla\n=======\n\n**Vanilla** is a simple accelerator consisting of a MAC array and has no\ninternal memory. It is can ONLY process Conv2D layers, all other layers\nare executed on a CPU, that also orchestrates **Vanilla**. Both the CPU\nand Vanilla use a shared memory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![A block diagram of Vanilla](https://raw.githubusercontent.com/apache/tvm-site/main/images/tutorial/uma_vanilla_block_diagram.png){width=\"100.0%\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Vanilla** has a C interface `vanilla_conv2dnchw(...)`\\` for carrying\nout a Conv2D operation (including same-padding), that accepts pointers\nto input feature map, weights and result, as well as the dimensions of\n\\`Conv2D\\`: [oc]{.title-ref}, [iw]{.title-ref}, [ih]{.title-ref},\n[ic]{.title-ref}, [kh]{.title-ref}, [kw]{.title-ref}.\n\n``` {.sourceCode .c++}\nint vanilla_conv2dnchw(float* ifmap, float*  weights, float*  result, int oc, int iw, int ih, int ic, int kh, int kw);\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The script [uma\\_cli]{.title-ref} creates code skeletons with API-calls\ninto the UMA-API for new accelerators.\n\nFor **Vanilla** we use it as follows: (`--tutorial vanilla` adds all the\nadditional files required for this part of the tutorial)\n\n``` {.sourceCode .bash}\npip install inflection\ncd $TVM_HOME/apps/uma\npython uma_cli.py --add_hardware vanilla_accelerator --tutorial vanilla\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "uma\\_cli.py generates these files in the directory `vanilla_accelerator`\nwhich we are going to revist.\n\n``` {.sourceCode .bash}\nbackend.py\ncodegen.py\nconv2dnchw.cc\npasses.py\npatterns.py\nrun.py\nstrategies.py\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vanilla backend\n\n> The generated backend for vanilla is found in\n> \\`vanilla\\_accelerator/backend.py\\`:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``` {.sourceCode .python}\nclass VanillaAcceleratorBackend(UMABackend):\n    \"\"\"UMA backend for VanillaAccelerator.\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n        self._register_pattern(\"conv2d\", conv2d_pattern())\n        self._register_tir_pass(PassPhase.TIR_PHASE_0, VanillaAcceleratorConv2DPass())\n        self._register_codegen(fmt=\"c\", includes=gen_includes)\n\n    @property\n    def target_name(self):\n        return \"vanilla_accelerator\"\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define offloaded patterns\n\nTo specify that [Conv2D]{.title-ref} is offloaded to **Vanilla**, it is\ndescribed as Relay dataflow pattern\n([DFPattern](https://tvm.apache.org/docs/reference/langref/relay_pattern.html))\nin [vanilla\\_accelerator/patterns.py]{.title-ref}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``` {.sourceCode .python}\ndef conv2d_pattern():\n    pattern = is_op(\"nn.conv2d\")(wildcard(), wildcard())\n    pattern = pattern.has_attr({\"strides\": [1, 1]})\n    return pattern\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To map **Conv2D** operations from the input graph to **Vanilla**\\'s low\nlevel function call `vanilla_conv2dnchw(...)`, the TIR pass\n*VanillaAcceleratorConv2DPass* (that will be discussed later in this\ntutorial) is registered in [VanillaAcceleratorBackend]{.title-ref}.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Codegen\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The file `vanilla_accelerator/codegen.py` defines static C-code that is\nadded to the resulting C-Code generated by TVM\u015b C-Codegen in\n`gen_includes`. Here C-code is added to include **Vanilla**\\'s low level\nlibrary`vanilla_conv2dnchw()`.\n\n``` {.sourceCode .python}\ndef gen_includes() -> str:\n    topdir = pathlib.Path(__file__).parent.absolute()\n\n    includes = \"\"\n    includes += f'#include \"{topdir}/conv2dnchw.cc\"'\n    return includes\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As shown above in [VanillaAcceleratorBackend]{.title-ref} it is\nregistered to UMA with the [self.\\_register\\_codegen]{.title-ref}\n\n``` {.sourceCode .python}\nself._register_codegen(fmt=\"c\", includes=gen_includes)\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Building the Neural Network and run it on Vanilla\n\nTo demonstrate UMA\\'s functionality, we will generate C code for a\nsingle Conv2D layer and run it on the Vanilla accelerator. The file\n`vanilla_accelerator/run.py` provides a demo running a Conv2D layer\nmaking use of Vanilla\\'s C-API.\n\n``` {.sourceCode .python}\ndef main():\n    mod, inputs, output_list, runner = create_conv2d()\n\n    uma_backend = VanillaAcceleratorBackend()\n    uma_backend.register()\n    mod = uma_backend.partition(mod)\n    target = tvm.target.Target(\"vanilla_accelerator\", host=tvm.target.Target(\"c\"))\n\n    export_directory = tvm.contrib.utils.tempdir(keep_for_debug=True).path\n    print(f\"Generated files are in {export_directory}\")\n    compile_and_run(\n        AOTModel(module=mod, inputs=inputs, outputs=output_list),\n        runner,\n        interface_api=\"c\",\n        use_unpacked_api=True,\n        target=target,\n        test_dir=str(export_directory),\n    )\n\n\nmain()\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By running `vanilla_accelerator/run.py` the output files are generated\nin the model library format (MLF).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n\n``` {.sourceCode .bash}\nGenerated files are in /tmp/tvm-debug-mode-tempdirs/2022-07-13T13-26-22___x5u76h0p/00000\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\\'s examine the generated files:\n\nOutput:\n\n``` {.sourceCode .bash}\ncd /tmp/tvm-debug-mode-tempdirs/2022-07-13T13-26-22___x5u76h0p/00000\ncd build/\nls -1\n\ncodegen\nlib.tar\nmetadata.json\nparameters\nruntime\nsrc\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To evaluate the generated C code go to `codegen/host/src/default_lib2.c`\n\n``` {.sourceCode .bash}\ncd codegen/host/src/\nls -1\n\ndefault_lib0.c\ndefault_lib1.c\ndefault_lib2.c\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In [default\\_lib2.c]{.title-ref} you can now see that the generated code\ncalls into Vanilla\\'s C-API and executes a Conv2D layer:\n\n``` {.sourceCode .c++}\nTVM_DLL int32_t tvmgen_default_vanilla_accelerator_main_0(float* placeholder, float* placeholder1, float* conv2d_nchw, uint8_t* global_workspace_1_var) {\n     vanilla_accelerator_conv2dnchw(placeholder, placeholder1, conv2d_nchw, 32, 14, 14, 32, 3, 3);\n     return 0;\n}\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Strawberry\n==========\n\nComing soon \\...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Chocolate\n=========\n\nComing soon \\...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Request for Community Input\n===========================\n\nIf this tutorial **did not** fit to your accelerator, lease add your\nrequirements to the UMA thread in the TVM discuss forum:\n[Link](https://discuss.tvm.apache.org/t/rfc-uma-universal-modular-accelerator-interface/12039).\nWe are eager to extend this tutorial to provide guidance on making\nfurther classes of AI hardware accelerators TVM-ready using the UMA\ninterface.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "References\n==========\n\n\\[UMA-RFC\\] [UMA: Universal Modular Accelerator\nInterface](https://github.com/apache/tvm-rfcs/blob/main/rfcs/0060_UMA_Unified_Modular_Accelerator_Interface.md),\nTVM RFC, June 2022.\n\n\\[DFPattern\\] [Pattern Matching in\nRelay](https://tvm.apache.org/docs/reference/langref/relay_pattern.html)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}