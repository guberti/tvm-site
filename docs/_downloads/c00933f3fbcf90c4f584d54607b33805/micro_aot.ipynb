{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%%bash\n# Installs the latest dev build of TVM from PyPI. If you wish to build\n# from source, see https://tvm.apache.org/docs/install/from_source.html\npip install apache-tvm --pre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "microTVM Host-Driven AoT {#tutorial-micro-AoT}\n========================\n\n**Authors**: [Mehrdad Hessar](https://github.com/mehrdadh), [Alan\nMacDonald](https://github.com/alanmacd)\n\nThis tutorial is showcasing microTVM host-driven AoT compilation with a\nTFLite model. AoTExecutor reduces the overhead of parsing graph at\nruntime compared to GraphExecutor. Also, we can have better memory\nmanagement using ahead of time compilation. This tutorial can be\nexecuted on a x86 CPU using C runtime (CRT) or on Zephyr platform on a\nmicrocontroller/board supported by Zephyr.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# You can skip the following two sections (installing Zephyr and CMSIS-NN) if the following flag is False.\n# Installing Zephyr takes ~20 min.\nimport os\n\nuse_physical_hw = bool(os.getenv(\"TVM_MICRO_USE_HW\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import Python dependencies\n==========================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pathlib\nimport json\n\nimport tvm\nfrom tvm import relay\nfrom tvm.relay.backend import Executor, Runtime\nfrom tvm.contrib.download import download_testdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import a TFLite model\n=====================\n\nTo begin with, download and import a Keyword Spotting TFLite model. This\nmodel is originally from [MLPerf Tiny\nrepository](https://github.com/mlcommons/tiny). To test this model, we\nuse samples from [KWS dataset provided by\nGoogle](https://ai.googleblog.com/2017/08/launching-speech-commands-dataset.html).\n\n**Note:** By default this tutorial runs on x86 CPU using CRT, if you\nwould like to run on Zephyr platform you need to export\n[TVM\\_MICRO\\_USE\\_HW]{.title-ref} environment variable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "MODEL_URL = \"https://github.com/tlc-pack/web-data/raw/main/testdata/microTVM/model/keyword_spotting_quant.tflite\"\nMODEL_PATH = download_testdata(MODEL_URL, \"keyword_spotting_quant.tflite\", module=\"model\")\nSAMPLE_URL = \"https://github.com/tlc-pack/web-data/raw/main/testdata/microTVM/data/keyword_spotting_int8_6.pyc.npy\"\nSAMPLE_PATH = download_testdata(SAMPLE_URL, \"keyword_spotting_int8_6.pyc.npy\", module=\"data\")\n\ntflite_model_buf = open(MODEL_PATH, \"rb\").read()\ntry:\n    import tflite\n\n    tflite_model = tflite.Model.GetRootAsModel(tflite_model_buf, 0)\nexcept AttributeError:\n    import tflite.Model\n\n    tflite_model = tflite.Model.Model.GetRootAsModel(tflite_model_buf, 0)\n\ninput_shape = (1, 49, 10, 1)\nINPUT_NAME = \"input_1\"\nrelay_mod, params = relay.frontend.from_tflite(\n    tflite_model, shape_dict={INPUT_NAME: input_shape}, dtype_dict={INPUT_NAME: \"int8\"}\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining the target\n===================\n\nNow we need to define the target, runtime and executor. In this\ntutorial, we focused on using AOT host driven executor. We use the host\nmicro target which is for running a model on x86 CPU using CRT runtime\nor running a model with Zephyr platform on qemu\\_x86 simulator board. In\nthe case of a physical microcontroller, we get the target model for the\nphysical board (E.g. nucleo\\_l4r5zi) and pass it to\n[tvm.target.target.micro]{.title-ref} to create a full micro target.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Use the C runtime (crt) and enable static linking by setting system-lib to True\nRUNTIME = Runtime(\"crt\", {\"system-lib\": True})\n\n# Simulate a microcontroller on the host machine. Uses the main() from `src/runtime/crt/host/main.cc`.\n# To use physical hardware, replace \"host\" with something matching your hardware.\nTARGET = tvm.target.target.micro(\"host\")\n\n# Use the AOT executor rather than graph or vm executors. Don't use unpacked API or C calling style.\nEXECUTOR = Executor(\"aot\")\n\nif use_physical_hw:\n    boards_file = pathlib.Path(tvm.micro.get_microtvm_template_projects(\"zephyr\")) / \"boards.json\"\n    with open(boards_file) as f:\n        boards = json.load(f)\n    BOARD = os.getenv(\"TVM_MICRO_BOARD\", default=\"nucleo_l4r5zi\")\n    SERIAL = os.getenv(\"TVM_MICRO_SERIAL\", default=None)\n    TARGET = tvm.target.target.micro(boards[BOARD][\"model\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compile the model\n=================\n\nNow, we compile the model for the target:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with tvm.transform.PassContext(opt_level=3, config={\"tir.disable_vectorize\": True}):\n    module = tvm.relay.build(\n        relay_mod, target=TARGET, params=params, runtime=RUNTIME, executor=EXECUTOR\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a microTVM project\n=========================\n\nNow that we have the compiled model as an IRModule, we need to create a\nfirmware project to use the compiled model with microTVM. To do this, we\nuse Project API. We have defined CRT and Zephyr microTVM template\nprojects which are used for x86 CPU and Zephyr boards respectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "template_project_path = pathlib.Path(tvm.micro.get_microtvm_template_projects(\"crt\"))\nproject_options = {}  # You can use options to provide platform-specific options through TVM.\n\nif use_physical_hw:\n    template_project_path = pathlib.Path(tvm.micro.get_microtvm_template_projects(\"zephyr\"))\n    project_options = {\n        \"project_type\": \"host_driven\",\n        \"board\": BOARD,\n        \"serial_number\": SERIAL,\n        \"config_main_stack_size\": 4096,\n        \"cmsis_path\": \"/content/cmsis\"\n        if os.environ.get(\"CMSIS_PATH\") is None\n        else os.environ.get(\"CMSIS_PATH\"),\n        \"zephyr_base\": \"/content/zephyrproject/zephyr\"\n        if os.environ.get(\"ZEPHYR_BASE\") is None\n        else os.environ.get(\"ZEPHYR_BASE\"),\n    }\n\ntemp_dir = tvm.contrib.utils.tempdir()\ngenerated_project_dir = temp_dir / \"project\"\nproject = tvm.micro.generate_project(\n    template_project_path, module, generated_project_dir, project_options\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Build, flash and execute the model\n==================================\n\nNext, we build the microTVM project and flash it. Flash step is specific\nto physical microcontrollers and it is skipped if it is simulating a\nmicrocontroller via the host main.cc or if a Zephyr emulated board is\nselected as the target. Next, we define the labels for the model output\nand execute the model with a sample with expected value of 6 (label:\nleft).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "project.build()\nproject.flash()\n\nlabels = [\n    \"_silence_\",\n    \"_unknown_\",\n    \"yes\",\n    \"no\",\n    \"up\",\n    \"down\",\n    \"left\",\n    \"right\",\n    \"on\",\n    \"off\",\n    \"stop\",\n    \"go\",\n]\nwith tvm.micro.Session(project.transport()) as session:\n    aot_executor = tvm.runtime.executor.aot_executor.AotModule(session.create_aot_executor())\n    sample = np.load(SAMPLE_PATH)\n    aot_executor.get_input(INPUT_NAME).copyfrom(sample)\n    aot_executor.run()\n    result = aot_executor.get_output(0).numpy()\n    print(f\"Label is `{labels[np.argmax(result)]}` with index `{np.argmax(result)}`\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}